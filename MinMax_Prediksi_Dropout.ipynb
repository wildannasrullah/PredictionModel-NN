{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MinMax_Prediksi_StudentDropout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVUcuhbGWPHd"
      },
      "source": [
        "import numpy as np # used for handling numbers \n",
        "import pandas as pd # used for handling the dataset\n",
        "from sklearn.impute import SimpleImputer # used for handling missing data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
        "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
        "#from sklearn.preprocessing import StandardScaler # used for feature scaling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhvOdvHsJV49"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsGdLYsvWeip"
      },
      "source": [
        "dataset = pd.read_csv('datamahasiswa_proses_2.csv', delimiter=\";\") # to import the dataset into a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "H8S4TnK85SR8",
        "outputId": "269c8d0f-ff1a-45fa-cf54-3b86c5db8ff3"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alamat</th>\n",
              "      <th>PedidikanIbu</th>\n",
              "      <th>PendidikanBapak</th>\n",
              "      <th>PekerjaanIbu</th>\n",
              "      <th>PekerjaanBapak</th>\n",
              "      <th>Bekerja</th>\n",
              "      <th>LamaKuliah</th>\n",
              "      <th>SKSSemester</th>\n",
              "      <th>Keuangan</th>\n",
              "      <th>JumlahSKS</th>\n",
              "      <th>DataAbsen</th>\n",
              "      <th>NilaiTesMasuk</th>\n",
              "      <th>NilaiIPS</th>\n",
              "      <th>NilaiIPK</th>\n",
              "      <th>StatusDropout</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>93</td>\n",
              "      <td>5</td>\n",
              "      <td>80</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>6</td>\n",
              "      <td>85</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>93</td>\n",
              "      <td>8</td>\n",
              "      <td>85</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>8</td>\n",
              "      <td>80</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>2</td>\n",
              "      <td>85</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Alamat  PedidikanIbu  PendidikanBapak  ...  NilaiIPS  NilaiIPK  StatusDropout\n",
              "0         1             3                2  ...      3.18      3.11              0\n",
              "1         0             3                3  ...      3.26      3.18              0\n",
              "2         0             4                4  ...      3.18      3.11              0\n",
              "3         0             4                1  ...      3.26      3.19              0\n",
              "4         0             3                4  ...      3.10      3.06              0\n",
              "..      ...           ...              ...  ...       ...       ...            ...\n",
              "935       0             1                1  ...      4.00      3.83              2\n",
              "936       0             2                1  ...      4.00      3.83              2\n",
              "937       0             2                4  ...      4.00      3.85              2\n",
              "938       0             2                1  ...      4.00      3.85              2\n",
              "939       0             4                4  ...      4.00      3.84              2\n",
              "\n",
              "[940 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCqVyYXE5Hzh"
      },
      "source": [
        "# Splitting the attributes into independent and dependent attributes\n",
        "dataset = dataset.to_numpy() # ubah pd.Daraframe menjadi array numpy\n",
        "X = dataset[:, 0:14] # Which contains the features\n",
        "y = dataset[:, 14] # Which contains the target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLA-mrcuJSzE"
      },
      "source": [
        "Missing Value (Mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJHiGgxlWkMQ"
      },
      "source": [
        "# handling the missing data and replace missing values with nan from numpy and replace with mean of all the other values\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
        "imputer = imputer.fit(X[:, 0:])\n",
        "X[:, 0:] = imputer.transform(X[:, 0:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aGy4U4Rfchz",
        "outputId": "f4aad9b2-394b-4a55-b608-58da3b61491b"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.  ,  3.  ,  2.  , ..., 80.  ,  3.18,  3.11],\n",
              "       [ 0.  ,  3.  ,  3.  , ..., 85.  ,  3.26,  3.18],\n",
              "       [ 0.  ,  4.  ,  4.  , ..., 85.  ,  3.18,  3.11],\n",
              "       ...,\n",
              "       [ 0.  ,  2.  ,  4.  , ..., 85.  ,  4.  ,  3.85],\n",
              "       [ 0.  ,  2.  ,  1.  , ..., 80.  ,  4.  ,  3.85],\n",
              "       [ 0.  ,  4.  ,  4.  , ..., 85.  ,  4.  ,  3.84]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk4V1kmm4pEK"
      },
      "source": [
        "X = pd.DataFrame(data=X,  columns= ['Alamat','PendidikanIbu','PendidikanBapak','PekerjaanIbu','PekerjaanBapak',\n",
        "                 'Bekerja','LamaKuliah','SKSSemester','Keuangan','JumlahSKS',\n",
        "                 'DataAbsen','NilaiTesMasuk','NilaiIPS','NilaiIPK'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "1qRCsNtD270T",
        "outputId": "9e4a4708-4c04-41a5-8e51-c2a17c836b89"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alamat</th>\n",
              "      <th>PendidikanIbu</th>\n",
              "      <th>PendidikanBapak</th>\n",
              "      <th>PekerjaanIbu</th>\n",
              "      <th>PekerjaanBapak</th>\n",
              "      <th>Bekerja</th>\n",
              "      <th>LamaKuliah</th>\n",
              "      <th>SKSSemester</th>\n",
              "      <th>Keuangan</th>\n",
              "      <th>JumlahSKS</th>\n",
              "      <th>DataAbsen</th>\n",
              "      <th>NilaiTesMasuk</th>\n",
              "      <th>NilaiIPS</th>\n",
              "      <th>NilaiIPK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Alamat  PendidikanIbu  PendidikanBapak  ...  NilaiTesMasuk  NilaiIPS  NilaiIPK\n",
              "0       1.0            3.0              2.0  ...           80.0      3.18      3.11\n",
              "1       0.0            3.0              3.0  ...           85.0      3.26      3.18\n",
              "2       0.0            4.0              4.0  ...           85.0      3.18      3.11\n",
              "3       0.0            4.0              1.0  ...           85.0      3.26      3.19\n",
              "4       0.0            3.0              4.0  ...           80.0      3.10      3.06\n",
              "..      ...            ...              ...  ...            ...       ...       ...\n",
              "935     0.0            1.0              1.0  ...           85.0      4.00      3.83\n",
              "936     0.0            2.0              1.0  ...           80.0      4.00      3.83\n",
              "937     0.0            2.0              4.0  ...           85.0      4.00      3.85\n",
              "938     0.0            2.0              1.0  ...           80.0      4.00      3.85\n",
              "939     0.0            4.0              4.0  ...           85.0      4.00      3.84\n",
              "\n",
              "[940 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrN0jcuyhlL9"
      },
      "source": [
        "Min-Max Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI4_HblRhp4q",
        "outputId": "6f5c8d2c-2c77-4558-f233-4c99df324313"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.75       0.5        ... 0.25       0.795      0.58064516]\n",
            " [0.         0.75       0.75       ... 0.5        0.815      0.61827957]\n",
            " [0.         1.         1.         ... 0.5        0.795      0.58064516]\n",
            " ...\n",
            " [0.         0.5        1.         ... 0.5        1.         0.97849462]\n",
            " [0.         0.5        0.25       ... 0.25       1.         0.97849462]\n",
            " [0.         1.         1.         ... 0.5        1.         0.97311828]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F40nXjKHiMG"
      },
      "source": [
        "X = pd.DataFrame(data=X, columns= ['Alamat','PendidikanIbu','PendidikanBapak','PekerjaanIbu','PekerjaanBapak',\n",
        "                 'Bekerja','LamaKuliah','SKSSemester','Keuangan','JumlahSKS',\n",
        "                 'DataAbsen','NilaiTesMasuk','NilaiIPS','NilaiIPK'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "e7phivLxHwPH",
        "outputId": "c03d7dbf-085f-4a4a-9df2-5463ccbfa013"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alamat</th>\n",
              "      <th>PendidikanIbu</th>\n",
              "      <th>PendidikanBapak</th>\n",
              "      <th>PekerjaanIbu</th>\n",
              "      <th>PekerjaanBapak</th>\n",
              "      <th>Bekerja</th>\n",
              "      <th>LamaKuliah</th>\n",
              "      <th>SKSSemester</th>\n",
              "      <th>Keuangan</th>\n",
              "      <th>JumlahSKS</th>\n",
              "      <th>DataAbsen</th>\n",
              "      <th>NilaiTesMasuk</th>\n",
              "      <th>NilaiIPS</th>\n",
              "      <th>NilaiIPK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.580645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.618280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.580645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.623656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.553763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.967742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.967742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.978495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.978495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.973118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>940 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Alamat  PendidikanIbu  PendidikanBapak  ...  NilaiTesMasuk  NilaiIPS  NilaiIPK\n",
              "0       1.0           0.75             0.50  ...           0.25     0.795  0.580645\n",
              "1       0.0           0.75             0.75  ...           0.50     0.815  0.618280\n",
              "2       0.0           1.00             1.00  ...           0.50     0.795  0.580645\n",
              "3       0.0           1.00             0.25  ...           0.50     0.815  0.623656\n",
              "4       0.0           0.75             1.00  ...           0.25     0.775  0.553763\n",
              "..      ...            ...              ...  ...            ...       ...       ...\n",
              "935     0.0           0.25             0.25  ...           0.50     1.000  0.967742\n",
              "936     0.0           0.50             0.25  ...           0.25     1.000  0.967742\n",
              "937     0.0           0.50             1.00  ...           0.50     1.000  0.978495\n",
              "938     0.0           0.50             0.25  ...           0.25     1.000  0.978495\n",
              "939     0.0           1.00             1.00  ...           0.50     1.000  0.973118\n",
              "\n",
              "[940 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG4gsUBuJM3p"
      },
      "source": [
        "Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNiYiGyi3tDt",
        "outputId": "ab8f6cef-14fb-4b1c-dd62-a93998a3f066"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "threshold = 8  # the number of most relevant features #Revisi : (menggunakan rangking nilai information gain )\n",
        "high_score_features = []\n",
        "feature_scores = mutual_info_classif(X, y, random_state=0)\n",
        "for score, f_name in sorted(zip(feature_scores, X.columns), reverse=True)[:threshold]:\n",
        "        print(f_name, score)\n",
        "        high_score_features.append(f_name)\n",
        "X = X[high_score_features]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NilaiIPS 0.9347252748669964\n",
            "NilaiIPK 0.931673469242137\n",
            "JumlahSKS 0.3901146666293527\n",
            "Keuangan 0.33235344938115086\n",
            "LamaKuliah 0.3038692563009264\n",
            "SKSSemester 0.12156733507460271\n",
            "NilaiTesMasuk 0.06005184160934052\n",
            "PendidikanBapak 0.028895089771626692\n",
            "     NilaiIPS  NilaiIPK  JumlahSKS  ...  SKSSemester  NilaiTesMasuk  PendidikanBapak\n",
            "0       0.795  0.580645   0.772727  ...     0.869565           0.25             0.50\n",
            "1       0.815  0.618280   0.803030  ...     0.869565           0.50             0.75\n",
            "2       0.795  0.580645   0.772727  ...     0.869565           0.50             1.00\n",
            "3       0.815  0.623656   0.803030  ...     0.869565           0.50             0.25\n",
            "4       0.775  0.553763   0.575758  ...     0.869565           0.25             1.00\n",
            "..        ...       ...        ...  ...          ...            ...              ...\n",
            "935     1.000  0.967742   1.000000  ...     0.869565           0.50             0.25\n",
            "936     1.000  0.967742   1.000000  ...     0.869565           0.25             0.25\n",
            "937     1.000  0.978495   1.000000  ...     0.869565           0.50             1.00\n",
            "938     1.000  0.978495   1.000000  ...     0.869565           0.25             0.25\n",
            "939     1.000  0.973118   1.000000  ...     0.869565           0.50             1.00\n",
            "\n",
            "[940 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFkDOrm0Uyc",
        "outputId": "ddbfc442-ac19-4179-c0ed-e035e02a2f79"
      },
      "source": [
        "X=np.array(X)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.795     , 0.58064516, 0.77272727, ..., 0.86956522, 0.25      ,\n",
              "        0.5       ],\n",
              "       [0.815     , 0.61827957, 0.8030303 , ..., 0.86956522, 0.5       ,\n",
              "        0.75      ],\n",
              "       [0.795     , 0.58064516, 0.77272727, ..., 0.86956522, 0.5       ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [1.        , 0.97849462, 1.        , ..., 0.86956522, 0.5       ,\n",
              "        1.        ],\n",
              "       [1.        , 0.97849462, 1.        , ..., 0.86956522, 0.25      ,\n",
              "        0.25      ],\n",
              "       [1.        , 0.97311828, 1.        , ..., 0.86956522, 0.5       ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhOyiahZGw5"
      },
      "source": [
        "y = y.reshape(-1, 1)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()\n",
        "\n",
        "#y = pd.DataFrame.from_records(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFLqAkHN6zm4",
        "outputId": "a8091d6f-5442-43a5-fb63-1bbb702548fe"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sQ8UStJZld"
      },
      "source": [
        "Split Data Training 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24bm3xWykXR8",
        "outputId": "cb4cff42-83d0-447e-9e77-c033043fca65"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train_ratio = 0.70\n",
        "# validation_ratio = 0.10\n",
        "# test_ratio = 0.20\n",
        "train_ratio = 0.70\n",
        "validation_ratio = 0.20\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 70% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 20% of the initial data set\n",
        "X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(X_train, X_val, X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.75       0.54301075 0.77272727 ... 0.82608696 0.5        1.        ]\n",
            " [0.86       0.67204301 1.         ... 0.95652174 0.25       0.5       ]\n",
            " [0.965      0.87096774 1.         ... 0.82608696 0.5        1.        ]\n",
            " ...\n",
            " [0.9125     0.77956989 1.         ... 0.86956522 0.5        0.75      ]\n",
            " [0.9        0.75268817 1.         ... 0.86956522 0.25       0.75      ]\n",
            " [0.925      0.79569892 1.         ... 0.86956522 0.         0.5       ]] [[0.9375     0.82795699 1.         ... 0.82608696 0.5        0.75      ]\n",
            " [0.985      0.93548387 1.         ... 1.         0.         0.5       ]\n",
            " [0.84       0.65053763 1.         ... 0.86956522 0.5        0.5       ]\n",
            " ...\n",
            " [0.8825     0.71505376 1.         ... 0.82608696 0.25       0.75      ]\n",
            " [0.95       0.84408602 1.         ... 0.82608696 0.25       0.5       ]\n",
            " [0.5525     0.46774194 0.54545455 ... 0.82608696 0.25       1.        ]] [[0.9475     0.83870968 1.         ... 0.82608696 0.5        0.75      ]\n",
            " [0.985      0.93010753 1.         ... 1.         0.5        0.5       ]\n",
            " [0.9075     0.76344086 1.         ... 0.86956522 0.5        0.25      ]\n",
            " ...\n",
            " [0.9325     0.81182796 0.84848485 ... 0.95652174 0.         0.5       ]\n",
            " [0.8675     0.67741935 1.         ... 0.82608696 0.5        0.5       ]\n",
            " [0.9275     0.81182796 1.         ... 0.95652174 0.5        0.75      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFbQJR4SmIXq",
        "outputId": "9d3ed4f3-4310-4bb5-97a5-64fe8cd0371b"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(283, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNkrz6N8MW3j"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v81RrmeSkag7"
      },
      "source": [
        "**ALTERNATIF** **SEMENTARA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74fu1_WPlEFC"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAuB2g96C4Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef15fa17-ec20-4f9e-afbd-e227073268ac"
      },
      "source": [
        "nn = Sequential()\n",
        "nn.add(Dense(50, input_dim=8, activation='sigmoid'))\n",
        "nn.add(Dense(70, activation='sigmoid'))\n",
        "nn.add(Dense(3, activation='softmax'))\n",
        "nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#nn.compile(loss=tf.nn.nce_loss, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(nn.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                450       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 70)                3570      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 213       \n",
            "=================================================================\n",
            "Total params: 4,233\n",
            "Trainable params: 4,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsX9lvxBnDoA",
        "outputId": "32cee900-d5bb-4084-e87a-5727173bab8e"
      },
      "source": [
        "history = nn.fit(X_train, y_train, epochs=300, batch_size=20, validation_data=(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 42ms/step - loss: 1.0304 - accuracy: 0.5770 - val_loss: 0.9802 - val_accuracy: 0.5594\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9310 - accuracy: 0.6160 - val_loss: 0.9629 - val_accuracy: 0.5594\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.9640 - accuracy: 0.5845 - val_loss: 0.9564 - val_accuracy: 0.5594\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9494 - accuracy: 0.5831 - val_loss: 0.9631 - val_accuracy: 0.5594\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9075 - accuracy: 0.6213 - val_loss: 0.9644 - val_accuracy: 0.5594\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.9530 - accuracy: 0.5890 - val_loss: 0.9653 - val_accuracy: 0.5594\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9264 - accuracy: 0.6125 - val_loss: 0.9618 - val_accuracy: 0.5594\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9483 - accuracy: 0.5917 - val_loss: 0.9584 - val_accuracy: 0.5594\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9742 - accuracy: 0.5660 - val_loss: 0.9572 - val_accuracy: 0.5594\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9325 - accuracy: 0.6100 - val_loss: 0.9645 - val_accuracy: 0.5594\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9725 - accuracy: 0.5679 - val_loss: 0.9538 - val_accuracy: 0.5594\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9252 - accuracy: 0.6091 - val_loss: 0.9573 - val_accuracy: 0.5594\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.9869 - accuracy: 0.5609 - val_loss: 0.9543 - val_accuracy: 0.5594\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9035 - accuracy: 0.6169 - val_loss: 0.9516 - val_accuracy: 0.5594\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0102 - accuracy: 0.5353 - val_loss: 0.9506 - val_accuracy: 0.5594\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9580 - accuracy: 0.5623 - val_loss: 0.9498 - val_accuracy: 0.5594\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9843 - accuracy: 0.5504 - val_loss: 0.9541 - val_accuracy: 0.5594\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9176 - accuracy: 0.6082 - val_loss: 0.9481 - val_accuracy: 0.5594\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9163 - accuracy: 0.5977 - val_loss: 0.9406 - val_accuracy: 0.5594\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9416 - accuracy: 0.5774 - val_loss: 0.9432 - val_accuracy: 0.5594\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9651 - accuracy: 0.5462 - val_loss: 0.9458 - val_accuracy: 0.5594\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9413 - accuracy: 0.5760 - val_loss: 0.9441 - val_accuracy: 0.5594\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9309 - accuracy: 0.5773 - val_loss: 0.9341 - val_accuracy: 0.5594\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.6063 - val_loss: 0.9347 - val_accuracy: 0.5594\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.6042 - val_loss: 0.9379 - val_accuracy: 0.5594\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.5850 - val_loss: 0.9315 - val_accuracy: 0.5594\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.5726 - val_loss: 0.9259 - val_accuracy: 0.5594\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.6033 - val_loss: 0.9342 - val_accuracy: 0.5594\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8732 - accuracy: 0.6184 - val_loss: 0.9184 - val_accuracy: 0.5594\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8663 - accuracy: 0.6293 - val_loss: 0.9182 - val_accuracy: 0.5594\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9080 - accuracy: 0.5802 - val_loss: 0.9197 - val_accuracy: 0.5616\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8724 - accuracy: 0.6070 - val_loss: 0.9114 - val_accuracy: 0.5594\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.9148 - accuracy: 0.5635 - val_loss: 0.9050 - val_accuracy: 0.5616\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8685 - accuracy: 0.6046 - val_loss: 0.9068 - val_accuracy: 0.5616\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8705 - accuracy: 0.5992 - val_loss: 0.9004 - val_accuracy: 0.5639\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.6310 - val_loss: 0.8924 - val_accuracy: 0.5639\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8451 - accuracy: 0.6239 - val_loss: 0.8922 - val_accuracy: 0.5708\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8665 - accuracy: 0.6024 - val_loss: 0.8860 - val_accuracy: 0.5708\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8753 - accuracy: 0.5790 - val_loss: 0.8800 - val_accuracy: 0.5708\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8600 - accuracy: 0.5914 - val_loss: 0.8766 - val_accuracy: 0.5731\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8440 - accuracy: 0.5988 - val_loss: 0.8684 - val_accuracy: 0.5731\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8004 - accuracy: 0.6439 - val_loss: 0.8646 - val_accuracy: 0.5731\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.8363 - accuracy: 0.5971 - val_loss: 0.8573 - val_accuracy: 0.5753\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8188 - accuracy: 0.6120 - val_loss: 0.8564 - val_accuracy: 0.5731\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7759 - accuracy: 0.6455 - val_loss: 0.8469 - val_accuracy: 0.5753\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7970 - accuracy: 0.6331 - val_loss: 0.8417 - val_accuracy: 0.6142\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7866 - accuracy: 0.6496 - val_loss: 0.8338 - val_accuracy: 0.5799\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7585 - accuracy: 0.6509 - val_loss: 0.8285 - val_accuracy: 0.6096\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7782 - accuracy: 0.6930 - val_loss: 0.8195 - val_accuracy: 0.6347\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.7854 - accuracy: 0.6512 - val_loss: 0.8128 - val_accuracy: 0.5913\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7614 - accuracy: 0.6319 - val_loss: 0.8081 - val_accuracy: 0.6301\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.8112 - accuracy: 0.6480 - val_loss: 0.8000 - val_accuracy: 0.6416\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7310 - accuracy: 0.6899 - val_loss: 0.8059 - val_accuracy: 0.6279\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7378 - accuracy: 0.7091 - val_loss: 0.7865 - val_accuracy: 0.6416\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7567 - accuracy: 0.6647 - val_loss: 0.7796 - val_accuracy: 0.6416\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.7577 - accuracy: 0.6535 - val_loss: 0.7697 - val_accuracy: 0.6416\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.7210 - val_loss: 0.7735 - val_accuracy: 0.6416\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6734 - accuracy: 0.7400 - val_loss: 0.7609 - val_accuracy: 0.6416\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.7193 - accuracy: 0.6752 - val_loss: 0.7528 - val_accuracy: 0.6438\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.6839 - val_loss: 0.7498 - val_accuracy: 0.6438\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.7106 - val_loss: 0.7516 - val_accuracy: 0.6393\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.7126 - val_loss: 0.7397 - val_accuracy: 0.6416\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7428 - val_loss: 0.7304 - val_accuracy: 0.6461\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.6784 - val_loss: 0.7254 - val_accuracy: 0.6438\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6827 - val_loss: 0.7248 - val_accuracy: 0.6416\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6923 - val_loss: 0.7253 - val_accuracy: 0.6370\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.7417 - val_loss: 0.7151 - val_accuracy: 0.6438\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.7315 - val_loss: 0.7063 - val_accuracy: 0.6461\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.7156 - val_loss: 0.7091 - val_accuracy: 0.6438\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.6983 - val_loss: 0.7006 - val_accuracy: 0.6507\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.7311 - val_loss: 0.6963 - val_accuracy: 0.6507\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.7379 - val_loss: 0.6956 - val_accuracy: 0.6484\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7539 - val_loss: 0.6880 - val_accuracy: 0.6507\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.7348 - val_loss: 0.6827 - val_accuracy: 0.6484\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.7522 - val_loss: 0.6853 - val_accuracy: 0.6461\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.7486 - val_loss: 0.6768 - val_accuracy: 0.6484\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7259 - val_loss: 0.6747 - val_accuracy: 0.6438\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6272 - accuracy: 0.6944 - val_loss: 0.6729 - val_accuracy: 0.6484\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6137 - accuracy: 0.7093 - val_loss: 0.6739 - val_accuracy: 0.6438\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5735 - accuracy: 0.7544 - val_loss: 0.6683 - val_accuracy: 0.6507\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.7130 - val_loss: 0.6596 - val_accuracy: 0.6530\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7138 - val_loss: 0.6623 - val_accuracy: 0.6507\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7274 - val_loss: 0.6627 - val_accuracy: 0.6507\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.6912 - val_loss: 0.6514 - val_accuracy: 0.6507\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6262 - accuracy: 0.6541 - val_loss: 0.6536 - val_accuracy: 0.6575\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.7417 - val_loss: 0.6564 - val_accuracy: 0.6530\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.7381 - val_loss: 0.6465 - val_accuracy: 0.6598\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7582 - val_loss: 0.6441 - val_accuracy: 0.6553\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.7865 - val_loss: 0.6418 - val_accuracy: 0.6598\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7193 - val_loss: 0.6342 - val_accuracy: 0.6553\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7303 - val_loss: 0.6408 - val_accuracy: 0.6621\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.7410 - val_loss: 0.6355 - val_accuracy: 0.6621\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7399 - val_loss: 0.6288 - val_accuracy: 0.6644\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7236 - val_loss: 0.6297 - val_accuracy: 0.6644\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7374 - val_loss: 0.6317 - val_accuracy: 0.6689\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5609 - accuracy: 0.7302 - val_loss: 0.6236 - val_accuracy: 0.6621\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.7153 - val_loss: 0.6192 - val_accuracy: 0.6644\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7398 - val_loss: 0.6236 - val_accuracy: 0.6644\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7321 - val_loss: 0.6172 - val_accuracy: 0.6575\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7691 - val_loss: 0.6227 - val_accuracy: 0.6689\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7492 - val_loss: 0.6111 - val_accuracy: 0.6644\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7477 - val_loss: 0.6090 - val_accuracy: 0.6575\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.6958 - val_loss: 0.6149 - val_accuracy: 0.6689\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7625 - val_loss: 0.6146 - val_accuracy: 0.6735\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7210 - val_loss: 0.6046 - val_accuracy: 0.6553\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7791 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7324 - val_loss: 0.6010 - val_accuracy: 0.6553\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.7400 - val_loss: 0.6042 - val_accuracy: 0.6758\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7737 - val_loss: 0.6001 - val_accuracy: 0.6712\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7614 - val_loss: 0.5927 - val_accuracy: 0.6598\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7656 - val_loss: 0.5929 - val_accuracy: 0.6758\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7430 - val_loss: 0.5894 - val_accuracy: 0.6644\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7212 - val_loss: 0.5875 - val_accuracy: 0.6667\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7234 - val_loss: 0.5877 - val_accuracy: 0.6689\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7701 - val_loss: 0.5876 - val_accuracy: 0.6735\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7430 - val_loss: 0.5796 - val_accuracy: 0.6621\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7648 - val_loss: 0.5799 - val_accuracy: 0.6644\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7552 - val_loss: 0.5793 - val_accuracy: 0.6689\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7715 - val_loss: 0.5800 - val_accuracy: 0.6689\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7055 - val_loss: 0.5722 - val_accuracy: 0.6598\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7482 - val_loss: 0.5745 - val_accuracy: 0.6689\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7657 - val_loss: 0.5680 - val_accuracy: 0.6621\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7675 - val_loss: 0.5663 - val_accuracy: 0.6621\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7730 - val_loss: 0.5691 - val_accuracy: 0.6712\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7216 - val_loss: 0.5624 - val_accuracy: 0.6644\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7734 - val_loss: 0.5637 - val_accuracy: 0.6689\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7595 - val_loss: 0.5559 - val_accuracy: 0.6598\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7424 - val_loss: 0.5597 - val_accuracy: 0.6667\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7243 - val_loss: 0.5602 - val_accuracy: 0.6758\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7762 - val_loss: 0.5578 - val_accuracy: 0.6689\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7714 - val_loss: 0.5508 - val_accuracy: 0.6644\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7425 - val_loss: 0.5505 - val_accuracy: 0.6712\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7163 - val_loss: 0.5465 - val_accuracy: 0.6667\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7684 - val_loss: 0.5457 - val_accuracy: 0.6689\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7457 - val_loss: 0.5430 - val_accuracy: 0.6689\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7554 - val_loss: 0.5438 - val_accuracy: 0.6712\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7937 - val_loss: 0.5400 - val_accuracy: 0.6667\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7791 - val_loss: 0.5340 - val_accuracy: 0.6644\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7548 - val_loss: 0.5336 - val_accuracy: 0.6667\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7751 - val_loss: 0.5355 - val_accuracy: 0.6689\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7814 - val_loss: 0.5298 - val_accuracy: 0.6689\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7655 - val_loss: 0.5250 - val_accuracy: 0.6804\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7739 - val_loss: 0.5278 - val_accuracy: 0.6712\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7229 - val_loss: 0.5253 - val_accuracy: 0.6712\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7644 - val_loss: 0.5287 - val_accuracy: 0.6781\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7839 - val_loss: 0.5188 - val_accuracy: 0.7489\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7714 - val_loss: 0.5208 - val_accuracy: 0.6781\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7563 - val_loss: 0.5175 - val_accuracy: 0.6735\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7301 - val_loss: 0.5130 - val_accuracy: 0.6758\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7537 - val_loss: 0.5235 - val_accuracy: 0.6804\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7491 - val_loss: 0.5113 - val_accuracy: 0.7489\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7450 - val_loss: 0.5127 - val_accuracy: 0.6804\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7212 - val_loss: 0.5087 - val_accuracy: 0.6804\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.7837 - val_loss: 0.5047 - val_accuracy: 0.6804\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7559 - val_loss: 0.4996 - val_accuracy: 0.7489\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7456 - val_loss: 0.5064 - val_accuracy: 0.6849\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7735 - val_loss: 0.4978 - val_accuracy: 0.7648\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8110 - val_loss: 0.5017 - val_accuracy: 0.6849\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.7811 - val_loss: 0.4900 - val_accuracy: 0.7443\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8089 - val_loss: 0.4868 - val_accuracy: 0.7352\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7872 - val_loss: 0.4866 - val_accuracy: 0.7260\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7415 - val_loss: 0.4871 - val_accuracy: 0.6872\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7595 - val_loss: 0.4828 - val_accuracy: 0.7557\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7661 - val_loss: 0.4816 - val_accuracy: 0.7306\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.7966 - val_loss: 0.4778 - val_accuracy: 0.7443\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7645 - val_loss: 0.4730 - val_accuracy: 0.7717\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.7974 - val_loss: 0.4786 - val_accuracy: 0.7306\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.7996 - val_loss: 0.4748 - val_accuracy: 0.7534\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8018 - val_loss: 0.4677 - val_accuracy: 0.7717\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8272 - val_loss: 0.4708 - val_accuracy: 0.7260\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8001 - val_loss: 0.4612 - val_accuracy: 0.7854\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8256 - val_loss: 0.4627 - val_accuracy: 0.7580\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8341 - val_loss: 0.4652 - val_accuracy: 0.7808\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8366 - val_loss: 0.4550 - val_accuracy: 0.7785\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8203 - val_loss: 0.4553 - val_accuracy: 0.7854\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8388 - val_loss: 0.4569 - val_accuracy: 0.7489\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.7822 - val_loss: 0.4497 - val_accuracy: 0.7831\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8207 - val_loss: 0.4569 - val_accuracy: 0.7420\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.7942 - val_loss: 0.4447 - val_accuracy: 0.7991\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8284 - val_loss: 0.4447 - val_accuracy: 0.7831\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.8574 - val_loss: 0.4424 - val_accuracy: 0.7808\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8355 - val_loss: 0.4367 - val_accuracy: 0.8037\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8202 - val_loss: 0.4388 - val_accuracy: 0.7877\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8352 - val_loss: 0.4321 - val_accuracy: 0.7968\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8614 - val_loss: 0.4327 - val_accuracy: 0.7854\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8383 - val_loss: 0.4266 - val_accuracy: 0.8082\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8197 - val_loss: 0.4287 - val_accuracy: 0.7900\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8377 - val_loss: 0.4271 - val_accuracy: 0.7922\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8464 - val_loss: 0.4239 - val_accuracy: 0.7922\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8418 - val_loss: 0.4180 - val_accuracy: 0.8059\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8611 - val_loss: 0.4192 - val_accuracy: 0.8447\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8808 - val_loss: 0.4229 - val_accuracy: 0.7854\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8514 - val_loss: 0.4156 - val_accuracy: 0.8402\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8602 - val_loss: 0.4166 - val_accuracy: 0.7922\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8410 - val_loss: 0.4088 - val_accuracy: 0.8516\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8352 - val_loss: 0.4115 - val_accuracy: 0.7922\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8643 - val_loss: 0.4068 - val_accuracy: 0.8425\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3440 - accuracy: 0.8805 - val_loss: 0.4004 - val_accuracy: 0.8128\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8420 - val_loss: 0.4009 - val_accuracy: 0.8059\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8345 - val_loss: 0.3943 - val_accuracy: 0.8196\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8484 - val_loss: 0.3942 - val_accuracy: 0.8311\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8822 - val_loss: 0.3952 - val_accuracy: 0.8174\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2961 - accuracy: 0.8918 - val_loss: 0.3894 - val_accuracy: 0.8242\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8693 - val_loss: 0.3860 - val_accuracy: 0.8311\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8617 - val_loss: 0.3849 - val_accuracy: 0.8539\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.9316 - val_loss: 0.3837 - val_accuracy: 0.8265\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8972 - val_loss: 0.3836 - val_accuracy: 0.8174\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8541 - val_loss: 0.3783 - val_accuracy: 0.8288\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8606 - val_loss: 0.3767 - val_accuracy: 0.8584\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.8817 - val_loss: 0.3797 - val_accuracy: 0.8196\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8639 - val_loss: 0.3731 - val_accuracy: 0.8311\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.8535 - val_loss: 0.3692 - val_accuracy: 0.8447\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2812 - accuracy: 0.8961 - val_loss: 0.3665 - val_accuracy: 0.8630\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8889 - val_loss: 0.3660 - val_accuracy: 0.8402\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8556 - val_loss: 0.3659 - val_accuracy: 0.8333\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.9215 - val_loss: 0.3636 - val_accuracy: 0.8744\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2884 - accuracy: 0.8768 - val_loss: 0.3585 - val_accuracy: 0.8402\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.9046 - val_loss: 0.3535 - val_accuracy: 0.8676\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8721 - val_loss: 0.3573 - val_accuracy: 0.8402\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8845 - val_loss: 0.3540 - val_accuracy: 0.8653\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2597 - accuracy: 0.9400 - val_loss: 0.3553 - val_accuracy: 0.8402\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.8916 - val_loss: 0.3461 - val_accuracy: 0.8653\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.8788 - val_loss: 0.3442 - val_accuracy: 0.8904\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.9314 - val_loss: 0.3489 - val_accuracy: 0.8379\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.9048 - val_loss: 0.3460 - val_accuracy: 0.9110\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.9476 - val_loss: 0.3432 - val_accuracy: 0.8493\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8665 - val_loss: 0.3385 - val_accuracy: 0.8927\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.9494 - val_loss: 0.3362 - val_accuracy: 0.8676\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.8885 - val_loss: 0.3318 - val_accuracy: 0.8904\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.9463 - val_loss: 0.3375 - val_accuracy: 0.8493\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2623 - accuracy: 0.8865 - val_loss: 0.3306 - val_accuracy: 0.9041\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9647 - val_loss: 0.3277 - val_accuracy: 0.8904\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.9328 - val_loss: 0.3305 - val_accuracy: 0.8630\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3023 - accuracy: 0.8798 - val_loss: 0.3239 - val_accuracy: 0.9110\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9422 - val_loss: 0.3297 - val_accuracy: 0.8493\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 0.9205 - val_loss: 0.3218 - val_accuracy: 0.9201\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2702 - accuracy: 0.9480 - val_loss: 0.3224 - val_accuracy: 0.8630\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2801 - accuracy: 0.8849 - val_loss: 0.3163 - val_accuracy: 0.8904\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.9262 - val_loss: 0.3157 - val_accuracy: 0.8904\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.9240 - val_loss: 0.3143 - val_accuracy: 0.9110\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.9471 - val_loss: 0.3137 - val_accuracy: 0.8836\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.9150 - val_loss: 0.3158 - val_accuracy: 0.9224\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2295 - accuracy: 0.9653 - val_loss: 0.3108 - val_accuracy: 0.8676\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.8992 - val_loss: 0.3053 - val_accuracy: 0.8927\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2282 - accuracy: 0.9432 - val_loss: 0.3076 - val_accuracy: 0.8973\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.9262 - val_loss: 0.3028 - val_accuracy: 0.8973\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2568 - accuracy: 0.9225 - val_loss: 0.3122 - val_accuracy: 0.8562\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2434 - accuracy: 0.8743 - val_loss: 0.3002 - val_accuracy: 0.9224\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2638 - accuracy: 0.9360 - val_loss: 0.3006 - val_accuracy: 0.8950\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2530 - accuracy: 0.8983 - val_loss: 0.2991 - val_accuracy: 0.9315\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2400 - accuracy: 0.9588 - val_loss: 0.2985 - val_accuracy: 0.8836\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2456 - accuracy: 0.9260 - val_loss: 0.2933 - val_accuracy: 0.9132\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2147 - accuracy: 0.9474 - val_loss: 0.2941 - val_accuracy: 0.8950\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.9335 - val_loss: 0.2909 - val_accuracy: 0.8973\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9499 - val_loss: 0.2891 - val_accuracy: 0.9155\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9459 - val_loss: 0.2905 - val_accuracy: 0.8881\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2159 - accuracy: 0.9363 - val_loss: 0.2874 - val_accuracy: 0.9178\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2535 - accuracy: 0.9172 - val_loss: 0.2870 - val_accuracy: 0.8927\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2261 - accuracy: 0.9483 - val_loss: 0.2864 - val_accuracy: 0.9361\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9581 - val_loss: 0.2850 - val_accuracy: 0.8927\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9401 - val_loss: 0.2817 - val_accuracy: 0.9361\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9406 - val_loss: 0.2796 - val_accuracy: 0.8950\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9266 - val_loss: 0.2806 - val_accuracy: 0.9132\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9514 - val_loss: 0.2804 - val_accuracy: 0.9110\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9632 - val_loss: 0.2758 - val_accuracy: 0.9155\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9525 - val_loss: 0.2737 - val_accuracy: 0.9361\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9722 - val_loss: 0.2800 - val_accuracy: 0.8836\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9656 - val_loss: 0.2710 - val_accuracy: 0.9178\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9409 - val_loss: 0.2699 - val_accuracy: 0.9178\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9703 - val_loss: 0.2737 - val_accuracy: 0.8904\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9340 - val_loss: 0.2678 - val_accuracy: 0.9201\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9502 - val_loss: 0.2659 - val_accuracy: 0.9155\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9486 - val_loss: 0.2664 - val_accuracy: 0.9247\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.9678 - val_loss: 0.2649 - val_accuracy: 0.9110\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1982 - accuracy: 0.9768 - val_loss: 0.2629 - val_accuracy: 0.9178\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9515 - val_loss: 0.2611 - val_accuracy: 0.9201\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1953 - accuracy: 0.9607 - val_loss: 0.2626 - val_accuracy: 0.9338\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2081 - accuracy: 0.9450 - val_loss: 0.2654 - val_accuracy: 0.8950\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9259 - val_loss: 0.2574 - val_accuracy: 0.9406\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2146 - accuracy: 0.9643 - val_loss: 0.2585 - val_accuracy: 0.9155\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9493 - val_loss: 0.2671 - val_accuracy: 0.8858\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9303 - val_loss: 0.2601 - val_accuracy: 0.9429\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.9734 - val_loss: 0.2604 - val_accuracy: 0.8927\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1892 - accuracy: 0.9421 - val_loss: 0.2526 - val_accuracy: 0.9406\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1909 - accuracy: 0.9690 - val_loss: 0.2694 - val_accuracy: 0.8813\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9239 - val_loss: 0.2532 - val_accuracy: 0.9361\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9768 - val_loss: 0.2553 - val_accuracy: 0.8973\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 0.9465 - val_loss: 0.2511 - val_accuracy: 0.9361\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2045 - accuracy: 0.9544 - val_loss: 0.2474 - val_accuracy: 0.9247\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9450 - val_loss: 0.2484 - val_accuracy: 0.9178\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9425 - val_loss: 0.2476 - val_accuracy: 0.9247\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9437 - val_loss: 0.2487 - val_accuracy: 0.9452\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9797 - val_loss: 0.2449 - val_accuracy: 0.9201\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9399 - val_loss: 0.2440 - val_accuracy: 0.9361\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9605 - val_loss: 0.2430 - val_accuracy: 0.9224\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9547 - val_loss: 0.2423 - val_accuracy: 0.9338\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9538 - val_loss: 0.2421 - val_accuracy: 0.9178\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9670 - val_loss: 0.2399 - val_accuracy: 0.9338\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9574 - val_loss: 0.2402 - val_accuracy: 0.9384\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9720 - val_loss: 0.2423 - val_accuracy: 0.9132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TM1mukeIj49K",
        "outputId": "5ca0e43a-1999-4c73-fff4-c59ed17a0e34"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "l06M1ao8kGl8",
        "outputId": "db157752-add8-4aa7-c98c-d16438d54832"
      },
      "source": [
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Test'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8hKzecpkzCi"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyVX3aeIk2Ke"
      },
      "source": [
        "# evaluate the model\n",
        "# scores = nn.evaluate(X, y, verbose=0)\n",
        "# print(\"%s: %.2f%%\" % (nn.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_C1zLxP-Zm0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGepAHPz-lk0"
      },
      "source": [
        "**F1-Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERjiR6Wa-dLo"
      },
      "source": [
        "# predict probabilities for test set\n",
        "#y_pred = nn.predict(X_val)\n",
        "y_test_arg=np.argmax(y_test,axis=1)\n",
        "Y_pred = np.argmax(nn.predict(X_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86R-gvlL-fa7",
        "outputId": "c3948fc0-cf21-4677-fc0c-2b35fb6994c2"
      },
      "source": [
        "print(\"F1-Score : %.2f\" % f1_score(y_test_arg, Y_pred, average=\"micro\"))\n",
        "print(\"Precision : %.2f\" % precision_score(y_test_arg, Y_pred, average=\"micro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score : 0.97\n",
            "Precision : 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0eRSkz9-g8j",
        "outputId": "a640d658-524e-4482-bb7e-8c09642214fc"
      },
      "source": [
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test_arg, Y_pred))\n",
        "print(classification_report(y_test_arg, Y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 35   0   0]\n",
            " [  4  68   4]\n",
            " [  1   0 171]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93        35\n",
            "           1       1.00      0.89      0.94        76\n",
            "           2       0.98      0.99      0.99       172\n",
            "\n",
            "    accuracy                           0.97       283\n",
            "   macro avg       0.95      0.96      0.95       283\n",
            "weighted avg       0.97      0.97      0.97       283\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjqpi5-ukPSy"
      },
      "source": [
        "#ditambah F-Score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugUosQ7s-t2D"
      },
      "source": [
        "**SIMPAN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn67dHnoMyd0",
        "outputId": "c8cf1a96-7f65-499e-a9de-9bca9688c32d"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.10,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (56.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.30.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYkwgtBfN3br"
      },
      "source": [
        "import tensorflowjs as tfjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFpI9v6gNXjT"
      },
      "source": [
        "tfjs.converters.save_keras_model(nn, 'models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHCPmAlXwTif"
      },
      "source": [
        "# y_pred = nn.predict(X_test) #sklearn.metric f-one score / confusion  matrix \n",
        "# #w = nn.evaluate(X_test, y_test,verbose=1)\n",
        "# y_pred = pd.DataFrame.from_records(y_pred)\n",
        "# y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZApBJOi5OJJ"
      },
      "source": [
        "#data_test = pd.read_csv('datamahasiswa_campur2-angka-test2.csv', delimiter=\";\") # to import the dataset into a variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1DDzQ2s5Svo"
      },
      "source": [
        "#data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCtAQI7iAEUf"
      },
      "source": [
        "# data_test = data_test.to_numpy()\n",
        "# X_input = data_test[:, 0:8] # Which contains the features\n",
        "#y_pred = dataset[:, 8] # Which contains the target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GZ6th4JB_E8"
      },
      "source": [
        "#X_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyjanY1RCGjK"
      },
      "source": [
        "# X_input = pd.DataFrame(data=X_input,  columns= ['NilaiIPK','NilaiIPS','JumlahSK','Keuangan',\n",
        "#                                                 'NilaiTesMasuk','SemesterBerjalan','Bekerja','DataAbsen'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fGB1QuDDcvU"
      },
      "source": [
        "# X_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJgruJlE_7sW"
      },
      "source": [
        "# X_input = z_score(X_input)\n",
        "\n",
        "# X_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7fDxLwH5Xpt"
      },
      "source": [
        "#data_test=np.array(data_test, dtype=np.float)\n",
        "# y_predt = nn.predict(np.array(X_input))\n",
        "# y_predt = pd.DataFrame.from_records(y_predt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg_VD5IV5swE"
      },
      "source": [
        "# y_predt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}